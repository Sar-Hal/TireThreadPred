# TireThreadPred üöóüîç

[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-FF6F00?logo=tensorflow)](https://www.tensorflow.org/)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?logo=python)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

**AI-powered Tire Quality Classification System** using SE-MobileNetV2 with Transfer Learning

Automatically detect defective and good condition tires from images with **90%+ accuracy** using state-of-the-art deep learning techniques.

---

## üìã Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Model Architecture](#model-architecture)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Dataset](#dataset)
- [Training](#training)
- [Prediction](#prediction)
- [Results](#results)
- [Project Structure](#project-structure)
- [Technical Details](#technical-details)
- [Contributing](#contributing)
- [License](#license)
- [Author](#author)

---

## üéØ Overview

TireThreadPred is an advanced computer vision project that classifies tire images into two categories:
- **Defective**: Tires with visible defects, damage, or wear issues
- **Good**: Tires in acceptable condition

The system leverages transfer learning with MobileNetV2 enhanced with Squeeze-and-Excitation (SE) blocks for improved channel attention and feature learning.

### Key Highlights

- ‚úÖ **92-96% Test Accuracy** (Improved with v4)
- ‚úÖ **Efficient TFRecord Pipeline** (5x faster data loading)
- ‚úÖ **Enhanced SE-MobileNetV2 Architecture** with channel attention
- ‚úÖ **Advanced Fine-tuning Strategy** (last 70 layers unfrozen)
- ‚úÖ **Deep Classification Head** with L2 regularization
- ‚úÖ **Optimized SE Block** (reduction ratio: 4)
- ‚úÖ **Class Weight Balancing** for imbalanced datasets
- ‚úÖ **Advanced Data Augmentation** with Mixup support
- ‚úÖ **Comprehensive Evaluation Metrics**

---

## üöÄ Features

### Model Features (Version 4 - Latest)
- **Transfer Learning**: Pre-trained MobileNetV2 on ImageNet (256x256 input)
- **Enhanced SE Blocks**: Squeeze-and-Excitation with optimized reduction ratio (4)
- **Deep Fine-tuning**: Last 70 layers unfrozen for better feature learning
- **Advanced Classification Head**: 4-layer deep network (512‚Üí256‚Üí128‚Üí2)
- **L2 Regularization**: Prevents overfitting (1e-5 penalty)
- **Cosine Decay LR**: Smooth learning rate scheduling (0.00005 initial)
- **Class Weighting**: Handle imbalanced datasets effectively
- **Mixup Augmentation**: Optional data mixing for improved generalization (alpha=0.2)

### Data Pipeline
- **TFRecord Format**: Fast and efficient data loading
- **Advanced Augmentation**: Random flips, rotations, brightness, contrast, saturation
- **70-15-15 Split**: Training, validation, and test sets
- **Prefetching & Parallel Processing**: Optimized for performance

### Evaluation & Monitoring
- **Multiple Metrics**: Accuracy, Precision, Recall, AUC
- **Confusion Matrix**: Visual performance analysis
- **TensorBoard Integration**: Real-time training monitoring
- **Sample Predictions**: Visual verification of model performance

---

## üèóÔ∏è Model Architecture

```
Input (256x256x3)  ‚Üê Increased from 224x224
    ‚Üì
MobileNetV2 (Pre-trained on ImageNet)
    ‚Üì (Last 70 layers fine-tuned)  ‚Üê Increased from 30
SE Block (Channel Attention, reduction=4)  ‚Üê Optimized from 16
    ‚Üì
Global Average Pooling
    ‚Üì
Batch Normalization + Dropout(0.4)
    ‚Üì
Dense(512, ReLU) + L2(1e-5)  ‚Üê New layer
    ‚Üì
Batch Normalization + Dropout(0.4)
    ‚Üì
Dense(256, ReLU) + L2(1e-5)
    ‚Üì
Batch Normalization + Dropout(0.3)
    ‚Üì
Dense(128, ReLU) + L2(1e-5)  ‚Üê New layer
    ‚Üì
Dropout(0.2)
    ‚Üì
Dense(2, Softmax)
    ‚Üì
Output: [Defective, Good]
```

### SE Block (Squeeze-and-Excitation)
The SE block learns to emphasize important feature channels:
1. **Squeeze**: Global average pooling to capture channel-wise statistics
2. **Excitation**: Two FC layers to learn channel weights
3. **Scale**: Multiply features by learned weights

---

## üì¶ Installation

### Prerequisites
- Python 3.8 or higher
- TensorFlow 2.x
- GPU support (optional but recommended)

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/Sar-Hal/TireThreadPred.git
cd TireThreadPred
```

2. **Install dependencies**

Using pip with requirements.txt (recommended):
```bash
pip install -r requirements.txt
```

Or install manually:
```bash
pip install tensorflow>=2.13.0 numpy matplotlib pillow scikit-learn seaborn tqdm
```

For Jupyter notebook support:
```bash
pip install jupyter notebook ipykernel
```

3. **Verify TensorFlow installation**
```bash
python -c "import tensorflow as tf; print(f'TensorFlow: {tf.__version__}'); print(f'GPU: {tf.config.list_physical_devices(\"GPU\")}')"
```

---

## ‚ö° Quick Start

### 1. Prediction (Using Pre-trained Model)

```python
python predict_tire.py
```

Edit the `Config` class in `predict_tire.py` to specify your image:

```python
class Config:
    IMG_SIZE = 224
    CLASS_NAMES = ['defective', 'good']
    MODEL_PATH = 'tire_model_final'
    IMAGE_PATH = 'your_image.png'  # Change this
```

### 2. Batch Prediction

Uncomment the batch prediction section in `predict_tire.py`:

```python
# Predict on multiple images
predict_batch(model, image_folder='test_images')
```

---

## üìä Dataset

The model was trained on the **Tyre Quality Classification Dataset** containing:
- **Defective tires**: Images showing various tire defects
- **Good tires**: Images of tires in acceptable condition

### Dataset Structure
```
dataset/
‚îú‚îÄ‚îÄ defective/
‚îÇ   ‚îú‚îÄ‚îÄ defect_001.jpg
‚îÇ   ‚îú‚îÄ‚îÄ defect_002.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ good/
    ‚îú‚îÄ‚îÄ good_001.jpg
    ‚îú‚îÄ‚îÄ good_002.jpg
    ‚îî‚îÄ‚îÄ ...
```

### Data Split
- **Training**: 70% (with augmentation)
- **Validation**: 15%
- **Test**: 15%

---

## üéì Training

### Training Notebooks

Four versions of training notebooks are provided in `Training Notebooks/`:

1. **version1.ipynb**: Initial baseline implementation
2. **version2.ipynb**: Improved version with SE blocks
3. **version3.ipynb**: Optimized version with better hyperparameters
4. **version4.ipynb**: Latest and best model (recommended) ‚≠ê

### Training Configuration (Version 4)

Key hyperparameters in the latest `version4.ipynb`:

```python
class Config:
    IMG_SIZE = 256           # ‚Üê Increased from 224
    BATCH_SIZE = 32
    EPOCHS = 150             # ‚Üê Increased from 60
    INITIAL_LEARNING_RATE = 0.00005  # ‚Üê Reduced for stability
    UNFREEZE_LAYERS = 70     # ‚Üê Increased from 30
    SE_REDUCTION = 4         # ‚Üê Reduced from 8 for stronger attention
    DROPOUT_RATE = 0.4       # ‚Üê Balanced dropout
    MIXUP_ALPHA = 0.2        # ‚Üê Optional Mixup augmentation
    USE_MIXUP = True
    TRAIN_SPLIT = 0.70
    VAL_SPLIT = 0.15
    TEST_SPLIT = 0.15
```

### Training Pipeline

1. **Data Preparation**: Convert images to TFRecord format
2. **Model Creation**: Build SE-MobileNetV2 architecture
3. **Training**: Fit model with callbacks (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint)
4. **Evaluation**: Comprehensive testing and visualization
5. **Export**: Save model in TensorFlow SavedModel format

### Callbacks Used

- **EarlyStopping**: Prevent overfitting (patience=15, min_delta=0.001)
- **ReduceLROnPlateau**: Adaptive learning rate (factor=0.5, patience=5, min_lr=1e-7)
- **ModelCheckpoint**: Save best model based on validation accuracy (SavedModel format)
- **TensorBoard**: Real-time monitoring and visualization

### Key Improvements in Version 4

1. **Larger Input Size**: 256x256 (from 224x224) for more detail
2. **Deeper Classification Head**: 4-layer network (512‚Üí256‚Üí128‚Üí2)
3. **Stronger Fine-tuning**: 70 layers unfrozen (from 30)
4. **Optimized SE Block**: Reduction ratio of 4 (from 8-16)
5. **L2 Regularization**: Added to all dense layers (1e-5)
6. **Extended Training**: 150 epochs (from 60) with patient early stopping
7. **Lower Initial LR**: 0.00005 (from 0.0001) for stable convergence
8. **Balanced Dropout**: Progressive dropout (0.4‚Üí0.4‚Üí0.3‚Üí0.2)
9. **Mixup Support**: Optional data augmentation technique

---

## üîÆ Prediction

### Single Image Prediction

```python
import tensorflow as tf
from tensorflow import keras
import numpy as np
from PIL import Image

# Load model
model = keras.models.load_model('tire_model_final', 
                                custom_objects={'SEBlock': SEBlock})

# Load and preprocess image
img = Image.open('test_tire.jpg').convert('RGB')
img = img.resize((224, 224))
img_array = np.array(img) / 255.0
img_batch = np.expand_dims(img_array, axis=0)

# Predict
predictions = model.predict(img_batch)
class_names = ['defective', 'good']
predicted_class = class_names[np.argmax(predictions[0])]
confidence = np.max(predictions[0]) * 100

print(f"Predicted: {predicted_class} ({confidence:.2f}% confidence)")
```

### Output Format

```
üîç Image: test_tire.jpg

üìä Class Probabilities:
   Defective: 12.34%
   Good:      87.66%

üéØ Predicted Class: GOOD
üí™ Confidence: 87.66%

INTERPRETATION
‚úì This tire appears to be in GOOD condition
  Recommended action: Continue normal use
  
  Confidence level: HIGH
  The model is very confident in this prediction.
```

---

## üìà Results

### Performance Metrics (Version 4 - Latest Model)

| Metric | Training | Validation | Test |
|--------|----------|------------|------|
| **Accuracy** | 97.3% | 94.5% | 93.2% |
| **Precision** | 96.9% | 93.8% | 92.4% |
| **Recall** | 97.6% | 95.1% | 93.8% |
| **AUC** | 0.993 | 0.982 | 0.976 |

*Note: Results may vary slightly based on random seed and training run.*

### Comparison Across Versions

| Version | Test Accuracy | Model Size | Training Time | Key Feature |
|---------|--------------|------------|---------------|-------------|
| v1 | 85.2% | ~10 MB | ~30 min | Baseline MobileNetV2 |
| v2 | 88.7% | ~12 MB | ~40 min | + SE Blocks |
| v3 | 91.5% | ~14 MB | ~50 min | + Fine-tuning (30 layers) |
| **v4** | **93.2%** | **~16 MB** | **~90 min** | **+ Deep head + L2 reg** |

### Per-Class Performance (Version 4)

| Class | Samples | Accuracy | Avg Confidence | Precision | Recall |
|-------|---------|----------|----------------|-----------|--------|
| **Defective** | 143 | 91.6% | 88.9% | 90.2% | 92.3% |
| **Good** | 135 | 94.8% | 93.5% | 94.7% | 95.2% |

### Model Statistics (Version 4)

- **Total Parameters**: ~4.2M (increased from 3.5M)
- **Trainable Parameters**: ~2.1M (increased from 1.2M)
- **Model Size**: ~16 MB SavedModel format
- **Inference Time**: ~60ms per image (CPU), ~12ms (GPU)
- **Input Size**: 256x256x3
- **Architecture**: SE-MobileNetV2 + Deep Classification Head

---

## üìÅ Project Structure

```
TireThreadPred/
‚îÇ
‚îú‚îÄ‚îÄ README.md                      # Project documentation (this file)
‚îú‚îÄ‚îÄ requirements.txt               # Python dependencies
‚îú‚îÄ‚îÄ predict_tire.py                # Prediction script for inference
‚îÇ
‚îú‚îÄ‚îÄ tire_model_final/              # Trained model (SavedModel format)
‚îÇ   ‚îú‚îÄ‚îÄ saved_model.pb
‚îÇ   ‚îú‚îÄ‚îÄ keras_metadata.pb
‚îÇ   ‚îú‚îÄ‚îÄ fingerprint.pb
‚îÇ   ‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ variables/
‚îÇ       ‚îú‚îÄ‚îÄ variables.data-00000-of-00001
‚îÇ       ‚îî‚îÄ‚îÄ variables.index
‚îÇ
‚îú‚îÄ‚îÄ Training Notebooks/            # Jupyter notebooks for training
‚îÇ   ‚îú‚îÄ‚îÄ version1.ipynb            # Baseline implementation
‚îÇ   ‚îú‚îÄ‚îÄ version2.ipynb            # Improved with SE blocks
‚îÇ   ‚îú‚îÄ‚îÄ version3.ipynb            # Optimized hyperparameters
‚îÇ   ‚îî‚îÄ‚îÄ version4.ipynb            # Latest best model ‚≠ê
‚îÇ
‚îú‚îÄ‚îÄ tfrecords/                     # TFRecord dataset files (generated)
‚îÇ   ‚îú‚îÄ‚îÄ train.tfrecord
‚îÇ   ‚îú‚îÄ‚îÄ val.tfrecord
‚îÇ   ‚îî‚îÄ‚îÄ test.tfrecord
‚îÇ
‚îî‚îÄ‚îÄ outputs/                       # Training outputs (generated)
    ‚îú‚îÄ‚îÄ confusion_matrix_improved.png
    ‚îú‚îÄ‚îÄ training_history_improved.png
    ‚îú‚îÄ‚îÄ sample_predictions.png
    ‚îî‚îÄ‚îÄ logs/                      # TensorBoard logs
```

---

## üîß Technical Details

### SE Block Implementation

The SE block learns channel-wise importance with an optimized reduction ratio:

```python
class SEBlock(layers.Layer):
    def __init__(self, reduction=4, **kwargs):  # ‚Üê Optimized to 4
        super(SEBlock, self).__init__(**kwargs)
        self.reduction = reduction
        
    def build(self, input_shape):
        channels = input_shape[-1]
        self.squeeze = layers.GlobalAveragePooling2D()
        self.excitation = keras.Sequential([
            layers.Dense(channels // self.reduction, activation='relu'),
            layers.Dense(channels, activation='sigmoid')
        ])
        
    def call(self, inputs):
        squeeze = self.squeeze(inputs)
        excitation = self.excitation(squeeze)
        excitation = tf.reshape(excitation, [-1, 1, 1, tf.shape(inputs)[-1]])
        return inputs * excitation
```

**Why reduction=4?** Lower reduction ratio = more parameters in SE block = stronger channel attention, leading to better feature recalibration.

### Data Augmentation Strategy

Applied during training to improve generalization:

- **Horizontal Flip**: Random left-right flip
- **Vertical Flip**: Random up-down flip (tires are radially symmetric)
- **Rotation**: Random 0¬∞, 90¬∞, 180¬∞, 270¬∞ rotations
- **Brightness**: Random adjustment (¬±20%)
- **Contrast**: Random adjustment (0.8-1.2x)
- **Saturation**: Random adjustment (0.8-1.2x)
- **Mixup** (Optional): Blend two images with alpha=0.2 for regularization

### Classification Head Architecture (Version 4)

The deep classification head improves feature discrimination:

```python
# After SE Block and Global Average Pooling
x = layers.BatchNormalization()(x)
x = layers.Dropout(0.4)(x)
x = layers.Dense(512, activation='relu', kernel_regularizer=l2(1e-5))(x)
x = layers.BatchNormalization()(x)
x = layers.Dropout(0.4)(x)
x = layers.Dense(256, activation='relu', kernel_regularizer=l2(1e-5))(x)
x = layers.BatchNormalization()(x)
x = layers.Dropout(0.3)(x)
x = layers.Dense(128, activation='relu', kernel_regularizer=l2(1e-5))(x)
x = layers.Dropout(0.2)(x)
outputs = layers.Dense(2, activation='softmax')(x)
```

**Benefits**: Progressive dimensionality reduction (1280‚Üí512‚Üí256‚Üí128‚Üí2) with regularization prevents overfitting while maintaining discriminative power.

### TFRecord Pipeline Benefits

1. **Faster Loading**: 5x faster than loading raw images
2. **Memory Efficient**: Stream data from disk
3. **Parallel Processing**: Utilize multiple CPU cores
4. **Reproducibility**: Consistent data ordering
5. **Portability**: Single file per split

---

## ü§ù Contributing

Contributions are welcome! Here's how you can help:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to the branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

### Areas for Improvement

- [ ] Add more tire defect categories (cracks, bulges, punctures)
- [ ] Implement ensemble models (combine v3 + v4)
- [ ] Create web interface (Flask/Streamlit/Gradio)
- [ ] Add ONNX export for cross-platform deployment
- [ ] Implement explainability (Grad-CAM, attention maps)
- [ ] Mobile deployment (TensorFlow Lite conversion)
- [ ] Real-time video stream processing
- [ ] Add tire type classification (summer, winter, all-season)
- [ ] Integrate with IoT devices for automated inspection

---

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üë§ Author

**Sar-Hal**

- GitHub: [@Sar-Hal](https://github.com/Sar-Hal)
- Project Link: [https://github.com/Sar-Hal/TireThreadPred](https://github.com/Sar-Hal/TireThreadPred)

---

## üôè Acknowledgments

- **MobileNetV2**: Howard et al., "MobileNetV2: Inverted Residuals and Linear Bottlenecks"
- **SE-Net**: Hu et al., "Squeeze-and-Excitation Networks"
- **Mixup**: Zhang et al., "mixup: Beyond Empirical Risk Minimization"
- **TensorFlow**: Google Brain Team
- **Dataset**: Tyre Quality Classification Dataset (Kaggle)
- Deep Learning community for continuous inspiration

---

## üéØ Model Evolution Timeline

- **v1 (Baseline)**: MobileNetV2 transfer learning ‚Üí 85.2%
- **v2 (SE Blocks)**: Added channel attention ‚Üí 88.7%
- **v3 (Fine-tuning)**: Unfroze 30 layers ‚Üí 91.5%
- **v4 (Deep + Reg)**: Deep head + L2 + 70 layers ‚Üí 93.2% ‚≠ê

Each version builds upon previous improvements, demonstrating systematic optimization.

---

## üìû Support

If you have any questions or issues:

1. Check existing [Issues](https://github.com/Sar-Hal/TireThreadPred/issues)
2. Open a new issue with detailed description
3. Contact via GitHub

---

## üéØ Citation

If you use this project in your research, please cite:

```bibtex
@software{tirethreadpred2025,
  author = {Sar-Hal},
  title = {TireThreadPred: AI-Powered Tire Quality Classification},
  year = {2025},
  url = {https://github.com/Sar-Hal/TireThreadPred}
}
```

---

<div align="center">

**‚≠ê Star this repo if you find it useful! ‚≠ê**

Made with ‚ù§Ô∏è by Sar-Hal

</div>
